{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and ML with wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0     1    14.23        1.71  2.43               15.6        127   \n",
      "1     1    13.20        1.78  2.14               11.2        100   \n",
      "2     1    13.16        2.36  2.67               18.6        101   \n",
      "3     1    14.37        1.95  2.50               16.8        113   \n",
      "4     1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n",
      "(178, 14)\n"
     ]
    }
   ],
   "source": [
    "wine=pd.read_csv(\"https://assets.datacamp.com/production/course_6576/datasets/wine_types.csv\")\n",
    "print(wine.head())\n",
    "print(wine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling without normalizing\n",
    "Let's take a look at what might happen to your model's accuracy if you try to model data without doing some sort of standardization first. Here we have a subset of the wine dataset. One of the columns, Proline, has an extremely high variance compared to the other columns. This is an example of where a technique like log normalization would come in handy, which you'll learn about in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wine.drop(\"Type\",axis=1)\n",
    "y=wine[\"Type\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42592592592592593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log normalization in Python\n",
    "Now that we know that the `Proline` column in our wine dataset has a large amount of variance, let's log normalize it.\n",
    "\n",
    "`Numpy` has been imported as `np` in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99166.71735542428\n",
      "0.17231366191842018\n"
     ]
    }
   ],
   "source": [
    "# Print out the variance of the Proline column\n",
    "print(wine[\"Proline\"].var())\n",
    "\n",
    "# Apply the log normalization function to the Proline column\n",
    "wine[\"Proline_log\"] = np.log(wine[\"Proline\"])\n",
    "\n",
    "# Check the variance of the Proline column again\n",
    "print(wine[\"Proline_log\"].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling data - standardizing columns\n",
    "Since we know that the Ash, Alcalinity of ash, and Magnesium columns in the wine dataset are all on different scales, let's standardize them in a way that allows for use in a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Take a subset of the DataFrame you want to scale \n",
    "wine_subset = wine[[\"Ash\",\"Alcalinity of ash\",\"Magnesium\"]]\n",
    "\n",
    "# Apply the scaler to the DataFrame subset\n",
    "wine_subset_scaled = ss.fit_transform(wine_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN and SVC on scaled data\n",
    "The accuracy score on the unscaled wine dataset was decent, but we can likely do better if we scale the dataset. The process is mostly the same as the previous exercise, with the added step of scaling the data. Once again, the knn model as well as the X and y data and labels set have already been created for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# Create the scaling method.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Apply the scaling method to the dataset used for modeling.\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data.\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Score the model on the test data.\n",
    "print(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# Fit the svc model to the training data.\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "# Score the model on the test data.\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for correlated features\n",
    "Let's take a look at the wine dataset again, which is made up of continuous, numerical features. Run Pearson's correlation coefficient on the dataset to determine which columns are good candidates for eliminating. Then, remove those columns from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Type   Alcohol  Malic acid       Ash  \\\n",
      "Type                          1.000000 -0.328222    0.437776 -0.049643   \n",
      "Alcohol                      -0.328222  1.000000    0.094397  0.211545   \n",
      "Malic acid                    0.437776  0.094397    1.000000  0.164045   \n",
      "Ash                          -0.049643  0.211545    0.164045  1.000000   \n",
      "Alcalinity of ash             0.517859 -0.310235    0.288500  0.443367   \n",
      "Magnesium                    -0.209179  0.270798   -0.054575  0.286587   \n",
      "Total phenols                -0.719163  0.289101   -0.335167  0.128980   \n",
      "Flavanoids                   -0.847498  0.236815   -0.411007  0.115077   \n",
      "Nonflavanoid phenols          0.489109 -0.155929    0.292977  0.186230   \n",
      "Proanthocyanins              -0.499130  0.136698   -0.220746  0.009652   \n",
      "Color intensity               0.265668  0.546364    0.248985  0.258887   \n",
      "Hue                          -0.617369 -0.071747   -0.561296 -0.074667   \n",
      "OD280/OD315 of diluted wines -0.788230  0.072343   -0.368710  0.003911   \n",
      "Proline                      -0.633717  0.643720   -0.192011  0.223626   \n",
      "\n",
      "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "Type                                   0.517859  -0.209179      -0.719163   \n",
      "Alcohol                               -0.310235   0.270798       0.289101   \n",
      "Malic acid                             0.288500  -0.054575      -0.335167   \n",
      "Ash                                    0.443367   0.286587       0.128980   \n",
      "Alcalinity of ash                      1.000000  -0.083333      -0.321113   \n",
      "Magnesium                             -0.083333   1.000000       0.214401   \n",
      "Total phenols                         -0.321113   0.214401       1.000000   \n",
      "Flavanoids                            -0.351370   0.195784       0.864564   \n",
      "Nonflavanoid phenols                   0.361922  -0.256294      -0.449935   \n",
      "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
      "Color intensity                        0.018732   0.199950      -0.055136   \n",
      "Hue                                   -0.273955   0.055398       0.433681   \n",
      "OD280/OD315 of diluted wines          -0.276769   0.066004       0.699949   \n",
      "Proline                               -0.440597   0.393351       0.498115   \n",
      "\n",
      "                              Flavanoids  Nonflavanoid phenols  \\\n",
      "Type                           -0.847498              0.489109   \n",
      "Alcohol                         0.236815             -0.155929   \n",
      "Malic acid                     -0.411007              0.292977   \n",
      "Ash                             0.115077              0.186230   \n",
      "Alcalinity of ash              -0.351370              0.361922   \n",
      "Magnesium                       0.195784             -0.256294   \n",
      "Total phenols                   0.864564             -0.449935   \n",
      "Flavanoids                      1.000000             -0.537900   \n",
      "Nonflavanoid phenols           -0.537900              1.000000   \n",
      "Proanthocyanins                 0.652692             -0.365845   \n",
      "Color intensity                -0.172379              0.139057   \n",
      "Hue                             0.543479             -0.262640   \n",
      "OD280/OD315 of diluted wines    0.787194             -0.503270   \n",
      "Proline                         0.494193             -0.311385   \n",
      "\n",
      "                              Proanthocyanins  Color intensity       Hue  \\\n",
      "Type                                -0.499130         0.265668 -0.617369   \n",
      "Alcohol                              0.136698         0.546364 -0.071747   \n",
      "Malic acid                          -0.220746         0.248985 -0.561296   \n",
      "Ash                                  0.009652         0.258887 -0.074667   \n",
      "Alcalinity of ash                   -0.197327         0.018732 -0.273955   \n",
      "Magnesium                            0.236441         0.199950  0.055398   \n",
      "Total phenols                        0.612413        -0.055136  0.433681   \n",
      "Flavanoids                           0.652692        -0.172379  0.543479   \n",
      "Nonflavanoid phenols                -0.365845         0.139057 -0.262640   \n",
      "Proanthocyanins                      1.000000        -0.025250  0.295544   \n",
      "Color intensity                     -0.025250         1.000000 -0.521813   \n",
      "Hue                                  0.295544        -0.521813  1.000000   \n",
      "OD280/OD315 of diluted wines         0.519067        -0.428815  0.565468   \n",
      "Proline                              0.330417         0.316100  0.236183   \n",
      "\n",
      "                              OD280/OD315 of diluted wines   Proline  \n",
      "Type                                             -0.788230 -0.633717  \n",
      "Alcohol                                           0.072343  0.643720  \n",
      "Malic acid                                       -0.368710 -0.192011  \n",
      "Ash                                               0.003911  0.223626  \n",
      "Alcalinity of ash                                -0.276769 -0.440597  \n",
      "Magnesium                                         0.066004  0.393351  \n",
      "Total phenols                                     0.699949  0.498115  \n",
      "Flavanoids                                        0.787194  0.494193  \n",
      "Nonflavanoid phenols                             -0.503270 -0.311385  \n",
      "Proanthocyanins                                   0.519067  0.330417  \n",
      "Color intensity                                  -0.428815  0.316100  \n",
      "Hue                                               0.565468  0.236183  \n",
      "OD280/OD315 of diluted wines                      1.000000  0.312761  \n",
      "Proline                                           0.312761  1.000000  \n",
      "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0     1    14.23        1.71  2.43               15.6        127   \n",
      "1     1    13.20        1.78  2.14               11.2        100   \n",
      "2     1    13.16        2.36  2.67               18.6        101   \n",
      "3     1    14.37        1.95  2.50               16.8        113   \n",
      "4     1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Nonflavanoid phenols  Proanthocyanins  Color intensity  \\\n",
      "0           2.80                  0.28             2.29             5.64   \n",
      "1           2.65                  0.26             1.28             4.38   \n",
      "2           2.80                  0.30             2.81             5.68   \n",
      "3           3.85                  0.24             2.18             7.80   \n",
      "4           2.80                  0.39             1.82             4.32   \n",
      "\n",
      "    Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0  1.04                          3.92     1065  \n",
      "1  1.05                          3.40     1050  \n",
      "2  1.03                          3.17     1185  \n",
      "3  0.86                          3.45     1480  \n",
      "4  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "wine=pd.read_csv(\"https://assets.datacamp.com/production/course_6576/datasets/wine_types.csv\")\n",
    "# Print out the column correlations of the wine dataset\n",
    "print(wine.corr())\n",
    "\n",
    "# Take a minute to find the column where the correlation value is greater than 0.75 at least twice\n",
    "to_drop = \"Flavanoids\"\n",
    "\n",
    "# Drop that column from the DataFrame\n",
    "wine = wine.drop(to_drop, axis=1)\n",
    "print(wine.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA\n",
    "Let's apply PCA to the wine dataset, to see if we can get an increase in our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.98098798e-01 1.73593305e-03 9.43282757e-05 4.89438533e-05\n",
      " 1.04695097e-05 5.60981698e-06 2.79968212e-06 1.44536313e-06\n",
      " 9.75418873e-07 3.94184513e-07 2.13661389e-07 8.91974959e-08]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "pca = PCA()\n",
    "wine_X = wine.drop(\"Type\", axis=1)\n",
    "y=wine[\"Type\"]\n",
    "\n",
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)\n",
    "\n",
    "# Look at the percentage of variance explained by the different components\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a123aa278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features=range(pca.n_components_)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(features,pca.explained_variance_)\n",
    "plt.xticks(features)\n",
    "plt.ylabel('variance')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407407\n"
     ]
    }
   ],
   "source": [
    "# Split the transformed X and the y labels into training and test sets\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit knn to the training data\n",
    "knn.fit(X_wine_train,y_wine_train)\n",
    "\n",
    "# Score knn on the test data and print it out\n",
    "print(knn.score(X_wine_test,y_wine_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4074074074074074\n"
     ]
    }
   ],
   "source": [
    "# Split the transformed X and the y labels into training and test sets\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit svc to the training data\n",
    "svc.fit(X_wine_train,y_wine_train)\n",
    "\n",
    "# Score svc on the test data and print it out\n",
    "print(svc.score(X_wine_test,y_wine_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 1)\n"
     ]
    }
   ],
   "source": [
    "pca1=PCA(n_components=1)\n",
    "pca1.fit(X)\n",
    "X_transformed1 = pca1.transform(X)\n",
    "print(X_transformed1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Split the transformed X and the y labels into training and test sets\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_transformed1, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit knn to the training data\n",
    "knn.fit(X_wine_train,y_wine_train)\n",
    "\n",
    "# Score knn on the test data and print it out\n",
    "print(knn.score(X_wine_test,y_wine_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5370370370370371\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_wine_train,y_wine_train)\n",
    "\n",
    "# Score svc on the test data and print it out\n",
    "print(svc.score(X_wine_test,y_wine_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
